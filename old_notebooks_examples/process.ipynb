{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to normalize alleles and haplotypes \n",
    "# when you use the tranlsate method for alleles that is already normalized \n",
    "# when you want to normalize a haplotype then you need to use the normalization method\n",
    "\n",
    "\n",
    "# normalizing haploytpes\n",
    "\n",
    "# from ga4gh.vrs.normalize import normalize\n",
    "# norm = normalize(This can be allele or haplotype, dp --- the database that you have been using)\n",
    "\n",
    "# https://normalize.cancervariants.org/variation#/\n",
    "\n",
    "# now for more complex hgvs expression like ones that have different ranges: you need to use VICC Variation normalizer\n",
    "\n",
    "# Example: \n",
    "    # NC_000023.10:g.(?_31645770)_(31792329_?)del\n",
    "\n",
    "    # the end point that i will be using is /variation/to_vrs\n",
    "\n",
    "\n",
    "#     {\n",
    "#   \"search_term\": \"NC_000023.10:g.(?_31645770)_(31792329_?)del\",\n",
    "#   \"warnings\": [],\n",
    "#   \"variations\": [\n",
    "#     {\n",
    "#       \"_id\": \"ga4gh:CX.9ylsEgpF1LmAti0XbNLeTtovkfzZUP-n\",\n",
    "#       \"type\": \"CopyNumberChange\",\n",
    "#       \"subject\": {\n",
    "#         \"_id\": \"ga4gh:VSL.njsf2Too-6iNCyDdDzPJHNSirD41Zbbs\",\n",
    "#         \"type\": \"SequenceLocation\",\n",
    "#         \"sequence_id\": \"ga4gh:SQ.v7noePfnNpK8ghYXEqZ9NukMXW7YeNsm\",\n",
    "#         \"interval\": {\n",
    "#           \"type\": \"SequenceInterval\",\n",
    "#           \"start\": {\n",
    "#             \"type\": \"IndefiniteRange\",\n",
    "#             \"value\": 31645769,\n",
    "#             \"comparator\": \"<=\"\n",
    "#           },\n",
    "#           \"end\": {\n",
    "#             \"type\": \"IndefiniteRange\",\n",
    "#             \"value\": 31792329,\n",
    "#             \"comparator\": \">=\"\n",
    "#           }\n",
    "#         }\n",
    "#       },\n",
    "#       \"copy_change\": \"efo:0030067\"\n",
    "#     }\n",
    "#   ],\n",
    "#   \"service_meta_\": {\n",
    "#     \"version\": \"0.5.5\",\n",
    "#     \"response_datetime\": \"2023-05-19T17:48:52.435887\",\n",
    "#     \"name\": \"variation-normalizer\",\n",
    "#     \"url\": \"https://github.com/cancervariants/variation-normalization\"\n",
    "#   }\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "class translate_api_fxn:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize class with the API URL\n",
    "        \"\"\"\n",
    "        \n",
    "        self.base_ncbi_url_api = 'https://api.ncbi.nlm.nih.gov/variation/v0/'\n",
    "        self.base_varnorm_url_api = 'https://normalize.cancervariants.org'\n",
    "\n",
    "        self.headers = {\n",
    "            'Content-Type': 'application/json; charset=utf-8'\n",
    "        }\n",
    "\n",
    "    def variation_to_vrs(self,q, untranslatable_returns_text='true'):\n",
    "        \n",
    "        endpoint = '/variation/to_vrs'\n",
    "\n",
    "        url = f'{self.base_varnorm_url_api}{endpoint}'\n",
    "        \n",
    "        params = {\n",
    "            'q': q,\n",
    "            'untranslatable_returns_text': untranslatable_returns_text\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, headers=self.headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return json.loads(response.text)['variations'][0]\n",
    "        else:\n",
    "            raise requests.HTTPError(f'Request failed with status code: {response.status_code}')\n",
    "\n",
    "    def spdi_attribute_concat(self,r):\n",
    "        \"\"\" \n",
    "        Extract spdi attributes,and concatenating the attributes to create a spdi syntax allele. \n",
    "        \"\"\"\n",
    "\n",
    "        reqjson = json.loads(r.text)\n",
    "        spdiobjs = reqjson['data']['spdis'] #[0] Index at first position for the first spdi object. \n",
    "        expr_list = []\n",
    "        for spdiobj in spdiobjs:\n",
    "            spdi = ':'.join([\n",
    "                spdiobj['seq_id'],\n",
    "                str(spdiobj['position']),\n",
    "                spdiobj['deleted_sequence'],\n",
    "                spdiobj['inserted_sequence']])\n",
    "            expr_list.append(spdi)\n",
    "        return expr_list\n",
    "\n",
    "    def spdi_to_hgvs(self,spdi_id):\n",
    "\n",
    "        endpoint = '/spdi/{}/hgvs'.format(spdi_id)\n",
    "        \n",
    "        url = f'{self.base_ncbi_url_api}{endpoint}'\n",
    "\n",
    "        \n",
    "        response = requests.get(url,headers=self.headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return json.loads(response.text)['data']['hgvs']\n",
    "        else:\n",
    "            raise requests.HTTPError(f'Request failed with status code: {response.status_code}')\n",
    "        \n",
    "    def hgvs_to_spdi(self,hgvs_id, assembly ='GCF_000001405.38'):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            hgvs_id (_type_): _description_\n",
    "            assembly (str, optional): _description_. Defaults to 'GCF_000001405.38'.\n",
    "\n",
    "        Raises:\n",
    "            requests.HTTPError: _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        endpoint = '/hgvs/{}/contextuals{}'.format(hgvs_id,assembly)\n",
    "        \n",
    "        url = f'{self.base_ncbi_url_api}{endpoint}' \n",
    "\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return self.spdi_attribute_concat(response)[0] # if I only want back one spdi expression [0]\n",
    "        else:\n",
    "            raise requests.HTTPError(f'Request failed with status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing functions above and class\n",
    "\n",
    "api = translate_api_fxn()\n",
    "result = api.variation_to_vrs('NC_000023.10:g.(?_31645770)_(31792329_?)del') #'NM_002111.8:c.60_110dup'\n",
    "print(result)\n",
    "result2 = api.spdi_to_hgvs('NC_000001.10:12345:1:A')\n",
    "print(result2)\n",
    "result3 = api.hgvs_to_spdi('NC_000001.10:g.12346C>A')\n",
    "print(result3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/M278428/opt/anaconda3/envs/test_dev_vrs_installation/lib/python3.9/site-packages/python_jsonschema_objects/__init__.py:49: UserWarning: Schema version http://json-schema.org/draft-07/schema not recognized. Some keywords and features may not be supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from ga4gh.vrs.extras.variation_normalizer_rest_dp import VariationNormalizerRESTDataProxy\n",
    "from ga4gh.vrs.dataproxy import SeqRepoRESTDataProxy\n",
    "from ga4gh.vrs.extras.translator import Translator\n",
    "seqrepo_rest_service_url = \"https://services.genomicmedlab.org/seqrepo\"\n",
    "dp = SeqRepoRESTDataProxy(base_url=seqrepo_rest_service_url)\n",
    "tlr = Translator(data_proxy=dp)\n",
    "vnorm = VariationNormalizerRESTDataProxy()\n",
    "\n",
    "\n",
    "def from_spid_to_rightshift_hgvs(expression):    \n",
    "    api = translate_api_fxn()\n",
    "    try: \n",
    "        # Converting a allele in SPDI syntax to the right-shifted HGVS notation\n",
    "        return api.spdi_to_hgvs(expression)\n",
    "    except Exception as e: \n",
    "        # returns error produce by NCBI API \n",
    "        return '{}. Expression Error: {}'.format(e,expression)\n",
    "    \n",
    "\n",
    "from_spid_to_rightshift_hgvs('NC_000001.10:12345:1:A')\n",
    "    \n",
    "def from_hgvs_to_spdi(expression):\n",
    "    api = translate_api_fxn()\n",
    "    try: \n",
    "        # Converting a allele in SPDI syntax to the right-shifted HGVS notation\n",
    "        return api.hgvs_to_spdi(expression)\n",
    "    except Exception as e: \n",
    "        # returns error produce by NCBI API \n",
    "        return '{}. Expression Error: {}'.format(e,expression)  \n",
    "    \n",
    "from_hgvs_to_spdi('NC_000001.10:g.12346C>A')\n",
    "\n",
    "def to_vrs_object(expression):\n",
    "\n",
    "    api = translate_api_fxn()\n",
    "\n",
    "    try:\n",
    "        return api.variation_to_vrs(expression)\n",
    "    except Exception as e:\n",
    "        return '{}. Expression Error: {}'.format(e,expression)  \n",
    "\n",
    "to_vrs_object('NC_000006.12:g.[18130687T>C;18138997C>T]')\n",
    "\n",
    "def from_vrs_to_normalize_hgvs(vrs_object):\n",
    "    \n",
    "    pjo = tlr.translate_from(vrs_object,\"vrs\")\n",
    "\n",
    "    try:\n",
    "        return vnorm.to_hgvs(pjo)[0]\n",
    "    except Exception as e:\n",
    "        return '{} Expression Error: {}'.format(e,pjo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Future implementation\n",
    "\n",
    "import re\n",
    "\n",
    "#'NC_000023.10:g.(?_31645770)_(31792329_?)del','NM_002111.8:c.60_110dup',\n",
    "test = ['NC_000023.10:g.(?_31645770)_(31792329_?)del','NM_002111.8:c.60_110dup','NC_000001.10:12345:1:A','NC_000001.10:g.12346C>A','jo:12345:1:A']\n",
    "api = translate_api_fxn()\n",
    "\n",
    "def check_variation(input_string):\n",
    "    # Define regular hgvs and spdi expressions\n",
    "    hgvs_re = r'[^:]+:[cgnpr]\\.'  \n",
    "    spdi_re = r'(?P<ac>[^:]+):(?P<pos>\\d+):(?P<del_len_or_seq>\\w*):(?P<ins_seq>\\w*)' \n",
    "\n",
    "    # Check hgvs regular expression\n",
    "    if re.match(hgvs_re, input_string):\n",
    "        print('this is a correct hgvs expression {}'.format(input_string))\n",
    "\n",
    "    # Check spdi regular expression\n",
    "    elif re.match(spdi_re, input_string):\n",
    "        print('this is a correct spdi expression {}'.format(input_string))\n",
    "        \n",
    "    else:\n",
    "        print(\"String does not match any expected pattern.\")\n",
    "        \n",
    "# Test the function with different input strings\n",
    "for i in test: \n",
    "    check_variation(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: old way of translating functions\n",
    "\n",
    "class extra:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize class with the seqrepo rest api \n",
    "        \"\"\"\n",
    "        self.seqrepo_rest_service_url = \"https://services.genomicmedlab.org/seqrepo\"\n",
    "        self.dp = SeqRepoRESTDataProxy(base_url=self.seqrepo_rest_service_url)\n",
    "        self.tlr = Translator(self.dp)\n",
    "\n",
    "\n",
    "    def to_rightshift_hgvs(self,expression):\n",
    "        \"\"\"Converting SPDI allele expression into right shift normalized HGVS expressions.\n",
    "\n",
    "        Args:\n",
    "            expression (string): SPDI allele expression \n",
    "\n",
    "        Returns:\n",
    "            string: Right shift normalized HGVS expressions\n",
    "        \"\"\"\n",
    "        \n",
    "        try: \n",
    "            # Converting a allele in SPDI syntax to the right-shifted HGVS notation\n",
    "            return vs.spdi_to_hgvs(expression)\n",
    "        except Exception as e: \n",
    "            # returns error produce by NCBI API \n",
    "            return 'Error in expression {}'.format(e)\n",
    "\n",
    "    def to_fullynorm_hgvs(self,expression):\n",
    "        \"\"\"Converting SPDI allele expression into fully normalized HGVS expressions.\n",
    "\n",
    "        Args:\n",
    "            expression (string): SPDI allele expressions\n",
    "\n",
    "        Returns:\n",
    "            list: Fully normalized HGVS expressions\n",
    "        \"\"\"\n",
    "\n",
    "        vrs_alleles = []\n",
    "\n",
    "        try:\n",
    "            trans = self.tlr.translate_from(expression, 'spdi')\n",
    "            vrs_alleles.append(trans)\n",
    "        except Exception as e:\n",
    "            # returns error produce by translate_from method\n",
    "            vrs_alleles.append('Error in expression {}'.format(e))\n",
    "\n",
    "        for allele in vrs_alleles:\n",
    "            if isinstance(allele, str):\n",
    "                return allele\n",
    "            else:\n",
    "                hgvs_expression = vnorm.to_hgvs(allele, 'refseq')\n",
    "                return  hgvs_expression\n",
    "\n",
    "    def to_vrs_allele(self,expression):\n",
    "        \"\"\"Convert SPDI allele expression into VRS Allele Object\n",
    "\n",
    "\n",
    "        Args:\n",
    "            expression (string): SPDI allele expressions\n",
    "\n",
    "        Returns:\n",
    "            dictionary: (Key = ga4gh identifier, Value = VRS allele Object)\n",
    "        \"\"\"\n",
    "\n",
    "        vrs_alleles = {}\n",
    "\n",
    "        try:\n",
    "            trans = self.tlr.translate_from(expression)\n",
    "            vrs_alleles[ga4gh_identify(trans)] = trans.as_dict() #json.dumps(trans.as_dict())\n",
    "        except Exception as e:\n",
    "            # returns error produce by translate_from method\n",
    "            vrs_alleles[\"Error in expression\"] = '{}'.format(e)\n",
    "            \n",
    "        return vrs_alleles\n",
    "    \n",
    "    # Need to put this function in a different class. Also, don't think functions like this are nessary\n",
    "    # they constantly need to be reconfigured based off of the dictionary inputed. \n",
    "    def create_spdi_expression(self,expression):\n",
    "        \"\"\"Takes a spdi dictionary and creates a SPDI allele expression with the follow formate: RefSeq:Posotion:Deletion:Insertion\n",
    "\n",
    "        Args:\n",
    "            expression (dictionary): (Key = SPDI four attributes, Values=  Value of each attribute) \n",
    "\n",
    "        Returns:\n",
    "            string: SPDI allele expressions\n",
    "        \"\"\"\n",
    "        # This would change based off of the structure of the dictionary\n",
    "        spdiobjs = expression['data']['spdis'] \n",
    "        for spdiobj in spdiobjs:\n",
    "            spdi = ':'.join([\n",
    "                spdiobj['seq_id'],\n",
    "                str(spdiobj['position']),\n",
    "                spdiobj['deleted_sequence'],\n",
    "                spdiobj['inserted_sequence']])\n",
    "            return spdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Understanding how to get normalized hgvs expression from vrs-python notebook\n",
    "\n",
    "import tabulate\n",
    "from ga4gh.core import ga4gh_identify\n",
    "from ga4gh.vrs.normalize import normalize\n",
    "from ga4gh.vrs.extras.variation_normalizer_rest_dp import VariationNormalizerRESTDataProxy\n",
    "from IPython.display import HTML, display\n",
    "vnorm = VariationNormalizerRESTDataProxy()\n",
    "\n",
    "\n",
    "#The postgres default port of 5432 is blocked outbound by binder and potentially other institutions. \n",
    "#To circumvent users having to install UTA themsleves we created a rest data proxy for variation normalizer for the to_hgvs endpoint.\n",
    "\n",
    "from ga4gh.vrs.dataproxy import SeqRepoRESTDataProxy\n",
    "from ga4gh.vrs.extras.translator import Translator\n",
    "seqrepo_rest_service_url = \"https://services.genomicmedlab.org/seqrepo\"\n",
    "dp = SeqRepoRESTDataProxy(base_url=seqrepo_rest_service_url)\n",
    "tlr = Translator(data_proxy=dp)\n",
    "\n",
    "# todo: this example should get changed to use normalized hgvs_g as input.\n",
    "tlr.normalize = False\n",
    "\n",
    "# Round-trip test: HGVS → VR Allele → HGVS[]\n",
    "header = \"check hgvs_orig sequence_id sequence_id_normalized hgvs_normalized\".split()\n",
    "table = [header]\n",
    "for hgvs_expr in (\n",
    "    \"NC_000013.11:g.32936732_32936733del\",\n",
    "    \"NC_000013.11:g.32936732_32936737del\",\n",
    "    \"NC_000013.11:g.32936732_32936733insC\",\n",
    "    \"NC_000013.11:g.32936732_32936733delinsC\",\n",
    "    \"NC_000013.11:g.32936732_32936735delinsC\",\n",
    "    \"NC_000013.11:g.32936732C>G\",\n",
    "    \"NM_015102.3:n.2802C>T\",\n",
    "    \"NC_000013.10:g.32331094_32331095dup\",\n",
    "    \"NC_000013.10:g.32331092_32331093insTA\"\n",
    "):\n",
    "    a = tlr.translate_from(hgvs_expr, \"hgvs\")\n",
    "    he = vnorm.to_hgvs(a)\n",
    "    chk = \"✔\" if hgvs_expr in he else \"✘\"\n",
    "    #print(f\"{chk} {hgvs_expr}\\n  → {ga4gh_identify(a)}\\n  → {he}\")\n",
    "    a_norm = normalize(a, dp)\n",
    "    row = [chk, hgvs_expr, ga4gh_identify(a), ga4gh_identify(a_norm), he[0] ]\n",
    "    table += [row]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: brain storming\n",
    "result = api.variation_to_vrs('NC_000023.10:g.(?_31645770)_(31792329_?)del') #'NM_002111.8:c.60_110dup'\n",
    "print(result)\n",
    "pjo = tlr.translate_from(result,\"vrs\")\n",
    "print(pjo)\n",
    "# print(vnorm.to_hgvs(pjo)[0])\n",
    "\n",
    "# # test1 = tlr.translate_from('NC_000023.10:g.(?_31645770)_(31792329_?)del', \"hgvs\")\n",
    "# # test1\n",
    "# anorm = []\n",
    "# for x in 'NC_000023.10:g.(?_31645770)_(31792329_?)del':\n",
    "#     result = api.variation_to_vrs(x) #'NM_002111.8:c.60_110dup'\n",
    "#     pjo = tlr.translate_from(result)\n",
    "#     a_norm.append(vnorm.to_hgvs(pjo))\n",
    "\n",
    "\n",
    "# mylist = []\n",
    "# for x in result:\n",
    "#     mylist.append(tlr.translate_from(x))\n",
    "\n",
    "# mylist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Variation normalizer returned the status code: 422. Expression Error: <CopyNumberChange attributes: _id, copy_change, subject, type>', 'NC_000013.11:g.32936732_32936733del', 'NC_000013.11:g.32936732_32936737del', 'NC_000013.11:g.32936733dup', 'NC_000013.11:g.32936733del']\n"
     ]
    }
   ],
   "source": [
    "api = translate_api_fxn()\n",
    "\n",
    "vrs_list = []\n",
    "var_list =['NC_000023.10:g.(?_31645770)_(31792329_?)del',\"NC_000013.11:g.32936732_32936733del\",\"NC_000013.11:g.32936732_32936737del\",\"NC_000013.11:g.32936732_32936733insC\",\"NC_000013.11:g.32936732_32936733delinsC\"]\n",
    "\n",
    "for var in var_list:\n",
    "   vrs_list.append(api.variation_to_vrs(var))\n",
    "\n",
    "norm_hgvs = []\n",
    "for vrs_obj in vrs_list:\n",
    "   norm_hgvs.append(from_vrs_to_normalize_hgvs(vrs_obj))\n",
    "\n",
    "print(norm_hgvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abc.Allele"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tlr.translate_from(vrs_list[1],\"vrs\")\n",
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_dev_vrs_installation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
